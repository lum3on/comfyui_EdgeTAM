# EdgeTAM ComfyUI Usage Guide

This guide provides detailed instructions for using EdgeTAM nodes in ComfyUI workflows.

## Quick Start

### 1. Installation

First, install EdgeTAM and its dependencies:

```bash
# Option 1: Use the installation script
python install_edgetam.py

# Option 2: Manual installation
git clone https://github.com/facebookresearch/EdgeTAM.git
cd EdgeTAM
pip install -e .
```

### 2. Test Installation

Verify everything is working:

```bash
python test_edgetam.py
```

## Node Reference

### EdgeTAM Video Tracker

Tracks objects across video frames using point or box prompts.

**Required Inputs:**
- `video_frames` (IMAGE): Batch of video frames

**Optional Inputs:**
- `prompt_points` (STRING): JSON array of [x, y] coordinates
- `prompt_labels` (STRING): JSON array of labels (1=include, 0=exclude)
- `click_x` (INT): X coordinate for single click point
- `click_y` (INT): Y coordinate for single click point
- `click_label` (COMBO): Label for single click point (include/exclude)
- `use_click_mode` (BOOLEAN): Use single click coordinates instead of JSON
- `model_path` (STRING): Custom model path
- `device` (COMBO): Computation device (auto/cuda/cpu/mps)
- `max_frames` (INT): Maximum frames to process
- `overlay_masks` (BOOLEAN): Show colored overlays

**Outputs:**
- `tracked_frames` (IMAGE): Original video frames
- `masks` (MASK): Segmentation masks for each frame
- `overlay_frames` (IMAGE): Frames with colored mask overlays

**Click Mode Example:**
```
use_click_mode: True
click_x: 320
click_y: 240
click_label: include
```

**JSON Mode Example:**
```json
{
  "prompt_points": "[[320, 240], [400, 300]]",
  "prompt_labels": "[1, 1]",
  "use_click_mode": false
}
```

### EdgeTAM Image Segmentor

Performs single-frame segmentation with SAM-like capabilities.

**Required Inputs:**
- `image` (IMAGE): Input image

**Optional Inputs:**
- `prompt_points` (STRING): JSON array of [x, y] coordinates
- `prompt_labels` (STRING): JSON array of labels (1=include, 0=exclude)
- `click_x` (INT): X coordinate for single click point
- `click_y` (INT): Y coordinate for single click point
- `click_label` (COMBO): Label for single click point (include/exclude)
- `use_click_mode` (BOOLEAN): Use single click coordinates instead of JSON
- `model_path` (STRING): Custom model path
- `device` (COMBO): Computation device (auto/cuda/cpu/mps)
- `multimask_output` (BOOLEAN): Return multiple mask predictions

**Outputs:**
- `mask` (MASK): Segmentation mask
- `overlay_image` (IMAGE): Image with colored mask overlay

**Click Mode Example:**
```
use_click_mode: True
click_x: 150
click_y: 200
click_label: include
```

**JSON Mode Example:**
```json
{
  "prompt_points": "[[150, 200], [300, 250]]",
  "prompt_labels": "[1, 0]",
  "use_click_mode": false
}
```

## Workflow Examples

### Basic Video Tracking

1. **Load Video**: Use `LoadVideo` node to load your video file
2. **Add Tracker**: Connect video to `EdgeTAMVideoTracker`
3. **Set Points**: Add click coordinates in `prompt_points`
4. **Set Labels**: Add corresponding labels in `prompt_labels`
5. **Preview/Save**: Connect outputs to preview or save nodes

### Multi-Object Tracking

For tracking multiple objects, use multiple tracker nodes:

```json
{
  "object1_points": "[[100, 100]]",
  "object1_labels": "[1]",
  "object2_points": "[[300, 200]]", 
  "object2_labels": "[1]"
}
```

### Image Segmentation Pipeline

1. **Load Image**: Use `LoadImage` node
2. **Segment**: Connect to `EdgeTAMImageSegmentor`
3. **Refine**: Use multiple points for better segmentation
4. **Post-process**: Apply mask operations as needed

## Tips and Best Practices

### Point Selection

- **Include points (label=1)**: Click inside the object you want to track
- **Exclude points (label=0)**: Click on areas you want to exclude
- **Multiple points**: Use several points for complex objects
- **Refinement**: Add exclude points to remove unwanted regions

### Performance Optimization

- **Device selection**: Use "cuda" for GPU acceleration
- **Frame limits**: Set `max_frames` for long videos
- **Batch processing**: Process videos in chunks for memory efficiency

### Common Issues

#### Model Download Fails
```bash
# Manual download
wget https://github.com/facebookresearch/EdgeTAM/releases/download/v1.0/edgetam.pt
# Place in: models/edgetam.pt
```

#### Memory Issues
- Reduce video resolution
- Process fewer frames at once
- Use CPU if GPU memory is limited

#### Poor Tracking Quality
- Add more include points on the object
- Add exclude points on background
- Ensure first frame has clear object visibility

## Advanced Usage

### Custom Model Paths

You can use custom trained models:

```json
{
  "model_path": "/path/to/custom/edgetam_model.pt"
}
```

### Coordinate Systems

Points are in image pixel coordinates:
- Origin (0,0) is top-left corner
- X increases rightward
- Y increases downward

### JSON Format Examples

**Single point:**
```json
{
  "prompt_points": "[[320, 240]]",
  "prompt_labels": "[1]"
}
```

**Multiple points:**
```json
{
  "prompt_points": "[[100, 100], [200, 150], [300, 200]]",
  "prompt_labels": "[1, 1, 0]"
}
```

**Complex object:**
```json
{
  "prompt_points": "[[150, 100], [200, 120], [180, 80], [250, 150]]",
  "prompt_labels": "[1, 1, 1, 0]"
}
```

## Integration with Other Nodes

### Video Processing Pipeline

```
LoadVideo ‚Üí EdgeTAMVideoTracker ‚Üí VideoProcessor ‚Üí SaveVideo
```

### Mask-based Workflows

```
EdgeTAMImageSegmentor ‚Üí MaskProcessor ‚Üí ImageComposite
```

### Batch Processing

```
ImageBatch ‚Üí EdgeTAMImageSegmentor ‚Üí MaskBatch ‚Üí BatchProcessor
```

## üéØ Visual Point Editor

EdgeTAM now includes an **advanced visual point editor** that makes point selection intuitive and precise:

### ‚ú® Features:

- **üñºÔ∏è Interactive Canvas**: Visual image display with real-time point placement
- **üé® Color-coded Points**: Green for include points, red for exclude points
- **üî¢ Point Numbering**: Clear numbering system for point order
- **üìù Live Coordinate Display**: Real-time coordinate feedback
- **üóëÔ∏è Individual Point Deletion**: Remove specific points with one click
- **üßπ Bulk Operations**: Clear all points or auto-generate labels
- **üìè Automatic Scaling**: Handles different image resolutions automatically

### üöÄ How to Use:

1. **Add EdgeTAM node** to your workflow
2. **Connect image/video source** to the node
3. **Scroll down** to find the **EdgeTAM Point Editor** below the text inputs
4. **Click "Load Image"** to display your image in the editor
5. **Select mode**: Choose "Include" or "Exclude" point type
6. **Click on the image** to add points where you want them
7. **Review points** in the point list below the image
8. **Delete individual points** using the √ó button if needed
9. **Points automatically sync** to the JSON text fields above

### üéÆ Editor Controls:

- **Include/Exclude Buttons**: Switch between point types
- **Clear All**: Remove all points and start over
- **Load Image**: Refresh the image display
- **Point List**: Shows all points with coordinates and types
- **Status Bar**: Real-time feedback and coordinate display

### üí° Pro Tips:

- **Automatic Label Sync**: The editor automatically updates both points and labels
- **Precise Coordinates**: Hover over the image to see exact pixel coordinates
- **Multiple Objects**: Use include points for objects, exclude points for background
- **Fine-tuning**: Add exclude points to remove unwanted areas from segmentation
- **Visual Feedback**: Green points = include, red points = exclude

### üîß Troubleshooting:

- **No image displayed**: Connect an image source and ensure it's properly loaded
- **Points not appearing**: Check that the image has loaded successfully
- **Coordinates seem wrong**: The editor automatically handles scaling - coordinates are in original image space
- **Editor not visible**: Scroll down below the text input fields to find the point editor

## üéØ Professional Points Editor Node

EdgeTAM now includes a **professional-grade Points Editor node** based on KJNodes architecture but optimized for EdgeTAM workflows:

### ‚ú® Key Features:

- **üñºÔ∏è Interactive Canvas**: Visual point placement with real-time feedback
- **‚å®Ô∏è Keyboard Shortcuts**: Professional hotkey system for efficient editing
- **üé® Color-Coded Points**: Green for positive (include), red for negative (exclude)
- **ÔøΩÔ∏è Intuitive Controls**: Shift+Click to add, Right-Click to delete
- **ÔøΩ Precise Coordinates**: Pixel-perfect point placement
- **üîÑ Format Conversion**: Automatic conversion to EdgeTAM format

### üöÄ Available Nodes:

#### üéØ EdgeTAM Points Editor
- **Inputs**: Canvas dimensions, background image (optional)
- **Outputs**: Positive coordinates, negative coordinates, preview image
- **Features**: KJNodes-style interactive point editor

#### ÔøΩ EdgeTAM Points Converter
- **Inputs**: Positive and negative coordinates from editor
- **Outputs**: Points JSON and Labels JSON for EdgeTAM nodes
- **Use**: Convert editor output to EdgeTAM tracker/segmentor format

### ‚å®Ô∏è Controls:

- **Shift + Left Click**: Add positive (green) point
- **Shift + Right Click**: Add negative (red) point
- **Right Click on Point**: Delete point
- **Drag Image**: Load background image to canvas
- **Copy/Paste**: Load image via clipboard

### üîß Example Workflows:

#### **Basic Point Selection:**
```
LoadImage ‚Üí EdgeTAM Points Editor ‚Üí EdgeTAM Points Converter ‚Üí EdgeTAM Video Tracker
```

#### **Advanced Multi-Point Tracking:**
```
LoadImage ‚Üí EdgeTAM Points Editor ‚Üí EdgeTAM Points Converter ‚Üí EdgeTAM Video Tracker
                ‚Üì                           ‚Üì
            Preview Image              Points + Labels
```

#### **Professional Workflow:**
```
LoadImage ‚Üí EdgeTAM Points Editor (Interactive Editing)
                ‚Üì
        EdgeTAM Points Converter (Format Conversion)
                ‚Üì
        EdgeTAM Video Tracker (Object Tracking)
                ‚Üì
        Preview Output (Results)
```

## Troubleshooting

### Installation Issues

1. **Python version**: Ensure Python ‚â• 3.10
2. **PyTorch version**: Ensure PyTorch ‚â• 2.3.1
3. **CUDA compatibility**: Match CUDA versions
4. **Dependencies**: Install all requirements

### Runtime Issues

1. **Import errors**: Run `python test_edgetam.py`
2. **Model loading**: Check model path and permissions
3. **Memory errors**: Reduce batch size or use CPU
4. **Performance**: Enable GPU acceleration

### Getting Help

- Check the test script output
- Review ComfyUI console logs
- Verify input formats (JSON syntax)
- Test with simple examples first

## Performance Benchmarks

Typical performance on different hardware:

- **RTX 4090**: ~30 FPS (1080p video)
- **RTX 3080**: ~20 FPS (1080p video)
- **Apple M2 Max**: ~15 FPS (1080p video)
- **CPU only**: ~2-5 FPS (1080p video)

Results may vary based on video complexity and tracking difficulty.
